{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":269740,"sourceType":"datasetVersion","datasetId":113003},{"sourceId":4243451,"sourceType":"datasetVersion","datasetId":32526},{"sourceId":9601762,"sourceType":"datasetVersion","datasetId":5668978},{"sourceId":10280684,"sourceType":"datasetVersion","datasetId":4892370}],"dockerImageVersionId":30823,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2025-01-02T11:01:11.001068Z","iopub.execute_input":"2025-01-02T11:01:11.001363Z","iopub.status.idle":"2025-01-02T11:01:11.349028Z","shell.execute_reply.started":"2025-01-02T11:01:11.001341Z","shell.execute_reply":"2025-01-02T11:01:11.348214Z"},"trusted":true},"outputs":[{"name":"stdout","text":"/kaggle/input/sarcasm/reddit_test.jsonl\n/kaggle/input/sarcasm/sarcasm_detection_shared_task_twitter_training.jsonl\n/kaggle/input/sarcasm/twitter_test.jsonl\n/kaggle/input/sarcasm/sarcasm_detection_shared_task_reddit_training.jsonl\n/kaggle/input/sarcasm/Ben-Sarc_ Bengali Sarcasm Detection Corpus.xlsx\n/kaggle/input/sarcasm/sarcasm_v2/RQ-sarc-notsarc.csv\n/kaggle/input/sarcasm/sarcasm_v2/GEN-sarc-notsarc.csv\n/kaggle/input/sarcasm/sarcasm_v2/HYP-sarc-notsarc.csv\n/kaggle/input/sarcastic-comments-on-reddit/train-balanced-sarcasm.csv\n/kaggle/input/news-category-dataset/News_Category_Dataset_v3.json\n/kaggle/input/personal-data/high_contrast.jpeg\n/kaggle/input/personal-data/1694354392633.jpg\n/kaggle/input/personal-data/Translation of banglaNewsData.xlsx\n/kaggle/input/personal-data/hindu.csv\n/kaggle/input/personal-data/political.txt\n/kaggle/input/personal-data/BanglaBlendCleanedData.xlsx\n/kaggle/input/personal-data/result31.csv\n/kaggle/input/personal-data/low_contrast_cat.jpeg\n/kaggle/input/personal-data/IMG_3661.jpg\n/kaggle/input/personal-data/Translator Dataset/Word.xlsx\n/kaggle/input/personal-data/Translator Dataset/Clause.xlsx\n/kaggle/input/personal-data/Translator Dataset/Sentence.xlsx\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"df = pd.read_excel('/kaggle/input/sarcasm/Ben-Sarc_ Bengali Sarcasm Detection Corpus.xlsx')\n\ndf.head(3)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-02T11:01:11.523587Z","iopub.execute_input":"2025-01-02T11:01:11.523980Z","iopub.status.idle":"2025-01-02T11:01:13.764204Z","shell.execute_reply.started":"2025-01-02T11:01:11.523957Z","shell.execute_reply":"2025-01-02T11:01:13.763466Z"}},"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"   id                                               Text  Polarity\n0   0  শুধু মাত্র এই পোস্টে কমেন্ট করার জন্য বাড়ির এ...         1\n1   2                             সাথে আছে বুক ভরা চুল ।         1\n2   4  ভাই মিথ্যা কথা বইলেন না আপনি ভিপিএন ইউজ করে পো...         1","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>Text</th>\n      <th>Polarity</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>শুধু মাত্র এই পোস্টে কমেন্ট করার জন্য বাড়ির এ...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>সাথে আছে বুক ভরা চুল ।</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>4</td>\n      <td>ভাই মিথ্যা কথা বইলেন না আপনি ভিপিএন ইউজ করে পো...</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":4},{"cell_type":"code","source":"df.rename(columns={\"Text\": \"text\"}, inplace=True)\ndf.rename(columns={\"Polarity\": \"label\"}, inplace=True)\n\ndf.head(3)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-02T11:01:13.765199Z","iopub.execute_input":"2025-01-02T11:01:13.765581Z","iopub.status.idle":"2025-01-02T11:01:13.775293Z","shell.execute_reply.started":"2025-01-02T11:01:13.765558Z","shell.execute_reply":"2025-01-02T11:01:13.774554Z"}},"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"   id                                               text  label\n0   0  শুধু মাত্র এই পোস্টে কমেন্ট করার জন্য বাড়ির এ...      1\n1   2                             সাথে আছে বুক ভরা চুল ।      1\n2   4  ভাই মিথ্যা কথা বইলেন না আপনি ভিপিএন ইউজ করে পো...      1","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>text</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>শুধু মাত্র এই পোস্টে কমেন্ট করার জন্য বাড়ির এ...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>সাথে আছে বুক ভরা চুল ।</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>4</td>\n      <td>ভাই মিথ্যা কথা বইলেন না আপনি ভিপিএন ইউজ করে পো...</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":5},{"cell_type":"code","source":"df['rtext'] = df['text'].apply(lambda x: ' '.join(x.split()[::-1]))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-02T11:01:14.270363Z","iopub.execute_input":"2025-01-02T11:01:14.270626Z","iopub.status.idle":"2025-01-02T11:01:14.326705Z","shell.execute_reply.started":"2025-01-02T11:01:14.270607Z","shell.execute_reply":"2025-01-02T11:01:14.326094Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"ri = 2\ndf['text'][ri], df['label'][ri]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-02T11:01:14.507797Z","iopub.execute_input":"2025-01-02T11:01:14.508139Z","iopub.status.idle":"2025-01-02T11:01:14.513091Z","shell.execute_reply.started":"2025-01-02T11:01:14.508100Z","shell.execute_reply":"2025-01-02T11:01:14.512435Z"}},"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"('ভাই মিথ্যা কথা বইলেন না আপনি ভিপিএন ইউজ করে পোস্ট দিয়েছেন এবং আপনি রঙিন দুনিয়া দেখছেন না । কারণ আপনার ফ্রেম রঙিন হলেও গ্লাসটা কিন্তু কালো । আমি কিন্তু রঙিন দুনিয়ার একজন রঙমিস্ত্রি তাই বিষয়টি এড়িয়ে যেতে পারলাম না ।',\n 1)"},"metadata":{}}],"execution_count":7},{"cell_type":"code","source":"df.label.value_counts()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-02T11:01:16.229045Z","iopub.execute_input":"2025-01-02T11:01:16.229326Z","iopub.status.idle":"2025-01-02T11:01:16.238880Z","shell.execute_reply.started":"2025-01-02T11:01:16.229305Z","shell.execute_reply":"2025-01-02T11:01:16.238045Z"}},"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"label\n1    12818\n0    12818\nName: count, dtype: int64"},"metadata":{}}],"execution_count":8},{"cell_type":"code","source":"df.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-02T11:01:16.429913Z","iopub.execute_input":"2025-01-02T11:01:16.430156Z","iopub.status.idle":"2025-01-02T11:01:16.434513Z","shell.execute_reply.started":"2025-01-02T11:01:16.430129Z","shell.execute_reply":"2025-01-02T11:01:16.433849Z"}},"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"(25636, 4)"},"metadata":{}}],"execution_count":9},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\n# Assume 'df' is your DataFrame and 'label_column' is the column you want to stratify on\n# df, _ = train_test_split(df, train_size=1000, stratify=df['label'], random_state=42)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-02T11:01:17.612913Z","iopub.execute_input":"2025-01-02T11:01:17.613194Z","iopub.status.idle":"2025-01-02T11:01:18.642799Z","shell.execute_reply.started":"2025-01-02T11:01:17.613173Z","shell.execute_reply":"2025-01-02T11:01:18.642190Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"print(df.shape)\ndf.head(3)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-02T11:01:18.643820Z","iopub.execute_input":"2025-01-02T11:01:18.644132Z","iopub.status.idle":"2025-01-02T11:01:18.652940Z","shell.execute_reply.started":"2025-01-02T11:01:18.644110Z","shell.execute_reply":"2025-01-02T11:01:18.652182Z"}},"outputs":[{"name":"stdout","text":"(25636, 4)\n","output_type":"stream"},{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"   id                                               text  label  \\\n0   0  শুধু মাত্র এই পোস্টে কমেন্ট করার জন্য বাড়ির এ...      1   \n1   2                             সাথে আছে বুক ভরা চুল ।      1   \n2   4  ভাই মিথ্যা কথা বইলেন না আপনি ভিপিএন ইউজ করে পো...      1   \n\n                                               rtext  \n0  ছিলাম বসে কিনে বি এম করে বিক্রি ঘোড়া পাড়া ডি...  \n1                             । চুল ভরা বুক আছে সাথে  \n2  । না পারলাম যেতে এড়িয়ে বিষয়টি তাই রঙমিস্ত্রি এ...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>text</th>\n      <th>label</th>\n      <th>rtext</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>শুধু মাত্র এই পোস্টে কমেন্ট করার জন্য বাড়ির এ...</td>\n      <td>1</td>\n      <td>ছিলাম বসে কিনে বি এম করে বিক্রি ঘোড়া পাড়া ডি...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>সাথে আছে বুক ভরা চুল ।</td>\n      <td>1</td>\n      <td>। চুল ভরা বুক আছে সাথে</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>4</td>\n      <td>ভাই মিথ্যা কথা বইলেন না আপনি ভিপিএন ইউজ করে পো...</td>\n      <td>1</td>\n      <td>। না পারলাম যেতে এড়িয়ে বিষয়টি তাই রঙমিস্ত্রি এ...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":11},{"cell_type":"code","source":"import pandas as pd\nimport json\n\n# Read the JSONL file\ndata_train = []\nwith open('/kaggle/input/sarcasm/sarcasm_detection_shared_task_reddit_training.jsonl', 'r') as f:\n    for line in f:\n        # Parse each line as JSON and append to list\n        data_train.append(json.loads(line))\ndata_twitter_df = pd.DataFrame(data_train)\n# Convert list of dictionaries to Data","metadata":{"execution":{"iopub.status.busy":"2025-01-02T11:01:18.654050Z","iopub.execute_input":"2025-01-02T11:01:18.654308Z","iopub.status.idle":"2025-01-02T11:01:18.704208Z","shell.execute_reply.started":"2025-01-02T11:01:18.654279Z","shell.execute_reply":"2025-01-02T11:01:18.703610Z"},"trusted":true},"outputs":[],"execution_count":12},{"cell_type":"code","source":"data_twitter_df['label']=data_twitter_df['label'].map({'SARCASM':0,'NOT_SARCASM':1})\ndata_twitter_df=data_twitter_df.rename(columns={'context':'parent_comment','response':'comment'})","metadata":{"execution":{"iopub.status.busy":"2025-01-02T11:01:19.377010Z","iopub.execute_input":"2025-01-02T11:01:19.377240Z","iopub.status.idle":"2025-01-02T11:01:19.384897Z","shell.execute_reply.started":"2025-01-02T11:01:19.377222Z","shell.execute_reply":"2025-01-02T11:01:19.384179Z"},"trusted":true},"outputs":[],"execution_count":13},{"cell_type":"code","source":"data_twitter_df.head(3)","metadata":{"execution":{"iopub.status.busy":"2025-01-02T11:01:19.529164Z","iopub.execute_input":"2025-01-02T11:01:19.529362Z","iopub.status.idle":"2025-01-02T11:01:19.536831Z","shell.execute_reply.started":"2025-01-02T11:01:19.529346Z","shell.execute_reply":"2025-01-02T11:01:19.536035Z"},"trusted":true},"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"   label                                            comment  \\\n0      0  Yeah I mean there's only one gender anyways, w...   \n1      0  Sounds like you don't like science, you theist...   \n2      0  Ofc play them in try mode, Blizzard were so ge...   \n\n                                      parent_comment  \n0  [LPT: If you're worried about hurting someone'...  \n1  [Promotional images for some guy's Facebook pa...  \n2  [My friends won't play Dota2; I won't play LoL...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>label</th>\n      <th>comment</th>\n      <th>parent_comment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>Yeah I mean there's only one gender anyways, w...</td>\n      <td>[LPT: If you're worried about hurting someone'...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>Sounds like you don't like science, you theist...</td>\n      <td>[Promotional images for some guy's Facebook pa...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>Ofc play them in try mode, Blizzard were so ge...</td>\n      <td>[My friends won't play Dota2; I won't play LoL...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":14},{"cell_type":"code","source":"data_twitter_df['comment']=data_twitter_df['comment'].astype(str)\ndata_twitter_df['parent_comment']=data_twitter_df['parent_comment'].astype(str)","metadata":{"execution":{"iopub.status.busy":"2025-01-02T11:01:20.931417Z","iopub.execute_input":"2025-01-02T11:01:20.931724Z","iopub.status.idle":"2025-01-02T11:01:20.944933Z","shell.execute_reply.started":"2025-01-02T11:01:20.931699Z","shell.execute_reply":"2025-01-02T11:01:20.944098Z"},"trusted":true},"outputs":[],"execution_count":15},{"cell_type":"code","source":"import torch\nfrom torch.utils.data import Dataset\n\nclass MultiFeatureDataset(Dataset):\n    def __init__(self, dataframe, tokenizer, max_len):\n        self.tokenizer = tokenizer\n        self.data = dataframe\n        self.comment = dataframe['comment']\n        self.parent=dataframe['parent_comment']\n        self.labels = dataframe.label\n        self.max_len = max_len\n\n    def __len__(self):\n        return len(self.data)\n    \n    def __getitem__(self, index):\n        if index >= len(self.data):\n            raise IndexError(f\"Index {index} out of range\")\n        comment = str(self.comment.iloc[index])\n        parent = str(self.parent.iloc[index])\n        label = self.labels.iloc[index]\n\n\n \n        comment_encoding = self.tokenizer.encode_plus(\n            comment,\n            add_special_tokens=True,\n            max_length=self.max_len,\n            return_token_type_ids=False,\n            padding='max_length',\n            truncation=True,\n            return_attention_mask=True,\n            return_tensors='pt',\n        )\n\n        parent_encoding = self.tokenizer.encode_plus(\n            parent,\n            add_special_tokens=True,\n            max_length=self.max_len,\n            return_token_type_ids=False,\n            padding='max_length',\n            truncation=True,\n            return_attention_mask=True,\n            return_tensors='pt',\n        )\n\n        return {\n        'input_ids1': parent_encoding['input_ids'].flatten(),\n        'attention_mask1': parent_encoding['attention_mask'].flatten(),\n        'input_ids2': comment_encoding['input_ids'].flatten(),\n        'attention_mask2': comment_encoding['attention_mask'].flatten(),\n        'labels': torch.tensor(label, dtype=torch.long)\n    }\n","metadata":{"execution":{"iopub.status.busy":"2025-01-02T11:01:22.366469Z","iopub.execute_input":"2025-01-02T11:01:22.366768Z","iopub.status.idle":"2025-01-02T11:01:25.245106Z","shell.execute_reply.started":"2025-01-02T11:01:22.366745Z","shell.execute_reply":"2025-01-02T11:01:25.244419Z"},"trusted":true},"outputs":[],"execution_count":16},{"cell_type":"code","source":"print(data_twitter_df.shape)\ndata_twitter_df.head(3)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-02T11:01:25.718196Z","iopub.execute_input":"2025-01-02T11:01:25.718557Z","iopub.status.idle":"2025-01-02T11:01:25.727330Z","shell.execute_reply.started":"2025-01-02T11:01:25.718534Z","shell.execute_reply":"2025-01-02T11:01:25.726427Z"}},"outputs":[{"name":"stdout","text":"(4400, 3)\n","output_type":"stream"},{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"   label                                            comment  \\\n0      0  Yeah I mean there's only one gender anyways, w...   \n1      0  Sounds like you don't like science, you theist...   \n2      0  Ofc play them in try mode, Blizzard were so ge...   \n\n                                      parent_comment  \n0  ['LPT: If you\\'re worried about hurting someon...  \n1  [\"Promotional images for some guy's Facebook p...  \n2  [\"My friends won't play Dota2; I won't play Lo...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>label</th>\n      <th>comment</th>\n      <th>parent_comment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>Yeah I mean there's only one gender anyways, w...</td>\n      <td>['LPT: If you\\'re worried about hurting someon...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>Sounds like you don't like science, you theist...</td>\n      <td>[\"Promotional images for some guy's Facebook p...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>Ofc play them in try mode, Blizzard were so ge...</td>\n      <td>[\"My friends won't play Dota2; I won't play Lo...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":17},{"cell_type":"code","source":"# df.rename(columns={\"Polarity\": \"label\"}, inplace=True)\ndf.rename(columns={\"text\": \"parent_comment\"}, inplace=True)\ndf.rename(columns={\"rtext\": \"comment\"}, inplace=True)\n\ndf.head(3)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-02T11:01:28.479808Z","iopub.execute_input":"2025-01-02T11:01:28.480149Z","iopub.status.idle":"2025-01-02T11:01:28.489337Z","shell.execute_reply.started":"2025-01-02T11:01:28.480121Z","shell.execute_reply":"2025-01-02T11:01:28.488557Z"}},"outputs":[{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"   id                                     parent_comment  label  \\\n0   0  শুধু মাত্র এই পোস্টে কমেন্ট করার জন্য বাড়ির এ...      1   \n1   2                             সাথে আছে বুক ভরা চুল ।      1   \n2   4  ভাই মিথ্যা কথা বইলেন না আপনি ভিপিএন ইউজ করে পো...      1   \n\n                                             comment  \n0  ছিলাম বসে কিনে বি এম করে বিক্রি ঘোড়া পাড়া ডি...  \n1                             । চুল ভরা বুক আছে সাথে  \n2  । না পারলাম যেতে এড়িয়ে বিষয়টি তাই রঙমিস্ত্রি এ...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>parent_comment</th>\n      <th>label</th>\n      <th>comment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>শুধু মাত্র এই পোস্টে কমেন্ট করার জন্য বাড়ির এ...</td>\n      <td>1</td>\n      <td>ছিলাম বসে কিনে বি এম করে বিক্রি ঘোড়া পাড়া ডি...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>সাথে আছে বুক ভরা চুল ।</td>\n      <td>1</td>\n      <td>। চুল ভরা বুক আছে সাথে</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>4</td>\n      <td>ভাই মিথ্যা কথা বইলেন না আপনি ভিপিএন ইউজ করে পো...</td>\n      <td>1</td>\n      <td>। না পারলাম যেতে এড়িয়ে বিষয়টি তাই রঙমিস্ত্রি এ...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":18},{"cell_type":"code","source":"data_twitter_df = df.copy()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-02T11:01:28.704778Z","iopub.execute_input":"2025-01-02T11:01:28.705022Z","iopub.status.idle":"2025-01-02T11:01:28.712342Z","shell.execute_reply.started":"2025-01-02T11:01:28.705001Z","shell.execute_reply":"2025-01-02T11:01:28.711666Z"}},"outputs":[],"execution_count":19},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\ntrain_df, eval_df = train_test_split(data_twitter_df, test_size=0.2, random_state=42, stratify=data_twitter_df['label'])\n\nprint(len(train_df), len(eval_df))","metadata":{"execution":{"iopub.status.busy":"2025-01-02T11:01:30.054382Z","iopub.execute_input":"2025-01-02T11:01:30.054698Z","iopub.status.idle":"2025-01-02T11:01:30.071732Z","shell.execute_reply.started":"2025-01-02T11:01:30.054665Z","shell.execute_reply":"2025-01-02T11:01:30.071030Z"},"trusted":true},"outputs":[{"name":"stdout","text":"20508 5128\n","output_type":"stream"}],"execution_count":20},{"cell_type":"code","source":"train_df.head(3)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-02T11:01:30.382061Z","iopub.execute_input":"2025-01-02T11:01:30.382420Z","iopub.status.idle":"2025-01-02T11:01:30.391069Z","shell.execute_reply.started":"2025-01-02T11:01:30.382389Z","shell.execute_reply":"2025-01-02T11:01:30.390235Z"}},"outputs":[{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"          id                                     parent_comment  label  \\\n24108  24487  আমার ভাই এবং বাবাকে নিয়ে নােয়াখালী সদর থানায...      0   \n16703  11100  যদি ডট বল করাতে চাও তবে আমাকে ডাকো সুনীল নারিন...      0   \n9138   22963     কেউ অক্সিজেন না পেয়ে মরে আর কেউ বিয়ে করে মরে ।      1   \n\n                                                 comment  \n24108  । পারেনি দিতে সন্ধান কোন আমাকে তারা চাইলে সন্ধ...  \n16703  । পানি বোতল এক ভিতর মরুভুমির । ছেলে সোনার আমাদ...  \n9138      । মরে করে বিয়ে কেউ আর মরে পেয়ে না অক্সিজেন কেউ  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>parent_comment</th>\n      <th>label</th>\n      <th>comment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>24108</th>\n      <td>24487</td>\n      <td>আমার ভাই এবং বাবাকে নিয়ে নােয়াখালী সদর থানায...</td>\n      <td>0</td>\n      <td>। পারেনি দিতে সন্ধান কোন আমাকে তারা চাইলে সন্ধ...</td>\n    </tr>\n    <tr>\n      <th>16703</th>\n      <td>11100</td>\n      <td>যদি ডট বল করাতে চাও তবে আমাকে ডাকো সুনীল নারিন...</td>\n      <td>0</td>\n      <td>। পানি বোতল এক ভিতর মরুভুমির । ছেলে সোনার আমাদ...</td>\n    </tr>\n    <tr>\n      <th>9138</th>\n      <td>22963</td>\n      <td>কেউ অক্সিজেন না পেয়ে মরে আর কেউ বিয়ে করে মরে ।</td>\n      <td>1</td>\n      <td>। মরে করে বিয়ে কেউ আর মরে পেয়ে না অক্সিজেন কেউ</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":21},{"cell_type":"code","source":"from transformers import AutoConfig, AutoModel, AutoTokenizer, logging\nimport torch\nimport torch.nn as nn\n\n# Suppress unnecessary warnings\nlogging.set_verbosity_error()\n\nclass CustomEncoderLayer(nn.Module):\n    def __init__(self, hidden_size, num_attention_heads, dropout_rate=0.3):\n        super(CustomEncoderLayer, self).__init__()\n        self.self_attention = nn.MultiheadAttention(hidden_size, num_attention_heads, dropout=dropout_rate)\n        self.cross_attention = nn.MultiheadAttention(hidden_size, num_attention_heads, dropout=dropout_rate)\n        self.feed_forward = nn.Sequential(\n            nn.Linear(hidden_size, hidden_size * 4),\n            nn.ReLU(),\n            nn.Linear(hidden_size * 4, hidden_size)\n        )\n        self.layer_norm1 = nn.LayerNorm(hidden_size)\n        self.layer_norm2 = nn.LayerNorm(hidden_size)\n        self.layer_norm3 = nn.LayerNorm(hidden_size)\n        self.dropout = nn.Dropout(dropout_rate)\n\n    def forward(self, x, y, x_mask, y_mask):\n        # Self-attention on x\n        temp1 = x\n        self_attn_output, _ = self.self_attention(x, x, x)\n        x = self.layer_norm1(temp1 + self.dropout(self_attn_output))\n        \n        # Cross-attention from x to y\n        cross_attn_output, cross_attn_weights = self.cross_attention(x, y, y)\n        x = self.layer_norm2(temp1 + self.dropout(cross_attn_output))\n        \n        # Feed forward\n        ff_output = self.feed_forward(x)\n        x = self.layer_norm3(temp1 + self.dropout(ff_output))\n        \n        return x, cross_attn_weights\n\nclass CustomDualBanglaBERTModel(nn.Module):\n    def __init__(self, model_checkpoint, num_layers=6, hidden_size=768, num_attention_heads=8, dropout_rate=0.1):\n        super(CustomDualBanglaBERTModel, self).__init__()\n        \n        # Load BanglaBERT Electra-based models\n        self.bert1 = AutoModel.from_pretrained(model_checkpoint)\n        self.bert2 = AutoModel.from_pretrained(model_checkpoint)\n        \n        # Custom encoder layers\n        self.encoder_layers = nn.ModuleList([\n            CustomEncoderLayer(hidden_size, num_attention_heads, dropout_rate)\n            for _ in range(num_layers)\n        ])\n        \n        # Classification head\n        self.fc = nn.Linear(hidden_size * 2, 2)\n\n    def forward(self, input_ids1, attention_mask1, input_ids2, attention_mask2):\n        # Get embeddings from two BERT models\n        output1 = self.bert1(input_ids=input_ids1, attention_mask=attention_mask1).last_hidden_state\n        output2 = self.bert2(input_ids=input_ids2, attention_mask=attention_mask2).last_hidden_state\n        \n        # Attention masks for padding tokens\n        x_mask = ~attention_mask1.bool()\n        y_mask = ~attention_mask2.bool()\n        \n        # Apply encoder layers\n        for layer in self.encoder_layers:\n            output1, _ = layer(output1, output2, x_mask, y_mask)\n            output2, cross_attn_weights = layer(output2, output1, y_mask, x_mask)\n        \n        # Pool the outputs from both models\n        pooled_output1 = torch.mean(output1, dim=1)\n        pooled_output2 = torch.mean(output2, dim=1)\n        \n        # Combine and classify\n        combined = torch.cat((pooled_output1, pooled_output2), dim=1)\n        return self.fc(combined)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-02T11:01:31.840859Z","iopub.execute_input":"2025-01-02T11:01:31.841147Z","iopub.status.idle":"2025-01-02T11:01:32.903848Z","shell.execute_reply.started":"2025-01-02T11:01:31.841126Z","shell.execute_reply":"2025-01-02T11:01:32.902976Z"}},"outputs":[],"execution_count":22},{"cell_type":"code","source":"# Example usage\nmodel_checkpoint = 'csebuetnlp/banglabert'\nmodel = CustomDualBanglaBERTModel(model_checkpoint=model_checkpoint)\n\n# Move the model to GPU if available\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n# model.to(device)\nmodel.cuda()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-02T11:01:35.130714Z","iopub.execute_input":"2025-01-02T11:01:35.131011Z","iopub.status.idle":"2025-01-02T11:01:43.469245Z","shell.execute_reply.started":"2025-01-02T11:01:35.130991Z","shell.execute_reply":"2025-01-02T11:01:43.468357Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/586 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ff1e83fb75014a94a1ee7a6e3268255c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/443M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c66548458d3146f1a3f03b338efdbb9e"}},"metadata":{}},{"execution_count":23,"output_type":"execute_result","data":{"text/plain":"CustomDualBanglaBERTModel(\n  (bert1): ElectraModel(\n    (embeddings): ElectraEmbeddings(\n      (word_embeddings): Embedding(32000, 768, padding_idx=0)\n      (position_embeddings): Embedding(512, 768)\n      (token_type_embeddings): Embedding(2, 768)\n      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (encoder): ElectraEncoder(\n      (layer): ModuleList(\n        (0-11): 12 x ElectraLayer(\n          (attention): ElectraAttention(\n            (self): ElectraSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): ElectraSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): ElectraIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): ElectraOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n    )\n  )\n  (bert2): ElectraModel(\n    (embeddings): ElectraEmbeddings(\n      (word_embeddings): Embedding(32000, 768, padding_idx=0)\n      (position_embeddings): Embedding(512, 768)\n      (token_type_embeddings): Embedding(2, 768)\n      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (encoder): ElectraEncoder(\n      (layer): ModuleList(\n        (0-11): 12 x ElectraLayer(\n          (attention): ElectraAttention(\n            (self): ElectraSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): ElectraSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): ElectraIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): ElectraOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n    )\n  )\n  (encoder_layers): ModuleList(\n    (0-5): 6 x CustomEncoderLayer(\n      (self_attention): MultiheadAttention(\n        (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n      )\n      (cross_attention): MultiheadAttention(\n        (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n      )\n      (feed_forward): Sequential(\n        (0): Linear(in_features=768, out_features=3072, bias=True)\n        (1): ReLU()\n        (2): Linear(in_features=3072, out_features=768, bias=True)\n      )\n      (layer_norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n      (layer_norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n      (layer_norm3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n  )\n  (fc): Linear(in_features=1536, out_features=2, bias=True)\n)"},"metadata":{}}],"execution_count":23},{"cell_type":"code","source":"# Calculate the total number of trainable parameters\ntrainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n\n# Each parameter takes 4 bytes (float32)\nparam_size_in_bytes = trainable_params * 4\n\n# Convert to GB\nparam_size_in_gb = param_size_in_bytes / (1024**3)\nprint(f\"Approximate Model Size in Memory: {param_size_in_gb:.2f} GB\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-02T11:01:52.961552Z","iopub.execute_input":"2025-01-02T11:01:52.962083Z","iopub.status.idle":"2025-01-02T11:01:52.969015Z","shell.execute_reply.started":"2025-01-02T11:01:52.962054Z","shell.execute_reply":"2025-01-02T11:01:52.967980Z"}},"outputs":[{"name":"stdout","text":"Approximate Model Size in Memory: 1.03 GB\n","output_type":"stream"}],"execution_count":24},{"cell_type":"code","source":"# import torch\n# import torch.nn as nn\n# from transformers import  BertConfig,AutoModel\n\n# class CustomEncoderLayer(nn.Module):\n#     def __init__(self, hidden_size, num_attention_heads, dropout_rate=0.1):\n#         super(CustomEncoderLayer, self).__init__()\n#         self.self_attention = nn.MultiheadAttention(hidden_size, num_attention_heads, dropout=dropout_rate)\n#         self.cross_attention = nn.MultiheadAttention(hidden_size, num_attention_heads, dropout=dropout_rate)\n#         self.feed_forward = nn.Sequential(\n#             nn.Linear(hidden_size, hidden_size * 4),\n#             nn.ReLU(),\n#             nn.Linear(hidden_size * 4, hidden_size)\n#         )\n#         self.layer_norm1 = nn.LayerNorm(hidden_size)\n#         self.layer_norm2 = nn.LayerNorm(hidden_size)\n#         self.layer_norm3 = nn.LayerNorm(hidden_size)\n#         self.dropout = nn.Dropout(dropout_rate)\n\n#     def forward(self, x, y):\n#         # Self-attention on x\n#         e=x\n#         self_attn_output, _ = self.self_attention(x, x, x)\n#         x = self.layer_norm1(e + self.dropout(self_attn_output))\n        \n#         # Cross-attention from x to y\n#         cross_attn_output, cross_attn_weights = self.cross_attention(x, y, y)\n#         x = self.layer_norm2(e + self.dropout(cross_attn_output))\n        \n#         # Feed forward\n#         ff_output = self.feed_forward(x)\n#         x = self.layer_norm3(e + self.dropout(ff_output))\n        \n#         return x, cross_attn_weights\n\n# class CustomDualBERTModel(nn.Module):\n#     def __init__(self, num_layers=3, hidden_size=768, num_attention_heads=8, dropout_rate=0.1):\n#         super(CustomDualBERTModel, self).__init__()\n        \n#         # Two BERT models: one for each input\n#         self.bert1 = AutoModel.from_pretrained('bert-base-uncased')\n#         self.bert2 = AutoModel.from_pretrained('bert-base-uncased')\n        \n#         self.encoder_layers = nn.ModuleList([\n#             CustomEncoderLayer(hidden_size, num_attention_heads, dropout_rate)\n#             for _ in range(num_layers)\n#         ])\n        \n#         self.fc = nn.Linear(hidden_size * 2, 2)\n\n#     def forward(self, input_ids1, attention_mask1, input_ids2, attention_mask2):\n#         # Get BERT embeddings from two different models\n#         output1 = self.bert1(input_ids=input_ids1, attention_mask=attention_mask1).last_hidden_state\n#         output2 = self.bert2(input_ids=input_ids2, attention_mask=attention_mask2).last_hidden_state\n        \n#         # Create attention masks\n#         x_mask = ~attention_mask1.bool()\n#         y_mask = ~attention_mask2.bool()\n        \n#         # Apply custom encoder layers (self-attention and cross-attention)\n#         for layer in self.encoder_layers:\n#             output1, _ = layer(output1, output2)\n#             output2, cross_attn_weights = layer(output2, output1)\n#         # Pool the outputs from both BERTs\n#         pooled_output1 = torch.mean(output1, dim=1)\n#         pooled_output2 = torch.mean(output2, dim=1)\n        \n#         # Combine and classify\n#         combined = torch.cat((pooled_output1, pooled_output2), dim=1)\n#         return self.fc(combined)\n","metadata":{"execution":{"iopub.status.busy":"2025-01-01T13:11:36.522650Z","iopub.execute_input":"2025-01-01T13:11:36.522924Z","iopub.status.idle":"2025-01-01T13:11:36.534748Z","shell.execute_reply.started":"2025-01-01T13:11:36.522902Z","shell.execute_reply":"2025-01-01T13:11:36.533935Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nfrom torch.utils.data import DataLoader\nfrom transformers import BertTokenizer, AdamW,AutoModel,AutoTokenizer\nfrom tqdm import tqdm  # Import tqdm for progress bars\n\n# Hyperparameters\nMAX_LEN = 128\nBATCH_SIZE = 16\nEPOCHS = 2\nLEARNING_RATE = 2e-5\n\ntokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n\n# Create data loaders\ntrain_dataset = MultiFeatureDataset(train_df, tokenizer, MAX_LEN)\nval_dataset = MultiFeatureDataset(eval_df, tokenizer, MAX_LEN)\n\ntrain_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\nval_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE)\n\n# Initialize the model\n\n# Usage\n# model = CustomDualBERTModel()\n#model.load_state_dict(torch.load('dual_bert_classifier.pth'))\n\n\n# Optimizer with weight decay\nfrom transformers import AdamW, get_linear_schedule_with_warmup\n\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nmodel = model.to(device)\n\noptimizer = AdamW(model.parameters(), lr=2e-5, weight_decay=0.01)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-02T11:05:06.150358Z","iopub.execute_input":"2025-01-02T11:05:06.150706Z","iopub.status.idle":"2025-01-02T11:05:07.214693Z","shell.execute_reply.started":"2025-01-02T11:05:06.150683Z","shell.execute_reply":"2025-01-02T11:05:07.213915Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/119 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5762c155a9834b04925a981db7a6c2c2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/528k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f240f3e07fa043018fe10f8936c7d271"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5d5ba03f677e4d95bab23f4da299b8d9"}},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n  warnings.warn(\n","output_type":"stream"}],"execution_count":25},{"cell_type":"code","source":"# Custom function to save the model\ndef save_model(model, filepath, epoch, val_accuracy, best_val_accuracy):\n    \"\"\"\n    Save the model if the current validation accuracy is higher than the best seen so far.\n    \"\"\"\n    if val_accuracy > best_val_accuracy:\n        torch.save(model.state_dict(), filepath)\n        print(f\"Model saved at epoch {epoch+1} with validation accuracy: {val_accuracy:.2f}%\")\n        return val_accuracy  # Update best validation accuracy\n    return best_val_accuracy  # Keep the previous best validation accuracy\n\n# Training loop with model saving\nbest_val_accuracy = 0.0  # Initialize the best validation accuracy\nmodel_filepath = 'dual_bert_classifier_best.pth'\n\nfor epoch in range(EPOCHS):\n    model.train()\n    running_loss = 0.0\n    correct_train = 0\n    total_train = 0\n\n    # Initialize the tqdm progress bar\n    progress_bar = tqdm(train_loader, desc=f\"Training Epoch {epoch+1}\", leave=False)\n    \n    for batch_idx, batch in enumerate(progress_bar):\n        text_input_ids1 = batch['input_ids1'].to(device)\n        text_attention_mask1 = batch['attention_mask1'].to(device)\n        text_input_ids2 = batch['input_ids2'].to(device)\n        text_attention_mask2 = batch['attention_mask2'].to(device)\n        labels = batch['labels'].to(device)\n        \n        optimizer.zero_grad()\n        \n        # Forward pass\n        outputs = model(text_input_ids1, text_attention_mask1, text_input_ids2, text_attention_mask2)\n        \n        # Calculate loss\n        loss = nn.CrossEntropyLoss()(outputs, labels)\n        \n        # Backward pass and optimization\n        loss.backward()\n        optimizer.step()\n        \n        # Update running loss and accuracy\n        running_loss += loss.item()\n        _, predicted = torch.max(outputs.data, 1)\n        total_train += labels.size(0)\n        correct_train += (predicted == labels).sum().item()\n        \n        avg_loss = running_loss / (batch_idx + 1)\n\n        # Update the progress bar with the average loss\n        progress_bar.set_postfix(avg_loss=avg_loss)\n\n    # Optional: Print statistics at the end of each epoch\n    epoch_loss = running_loss / len(train_loader)\n    epoch_acc = correct_train / total_train\n    print(f\"Epoch [{epoch+1}/{EPOCHS}], Loss: {epoch_loss:.4f}, Accuracy: {epoch_acc:.4f}\")\n    \n    # Validation\n    model.eval()\n    val_loss = 0\n    correct_val = 0\n    total_val = 0\n    with torch.no_grad():\n        for batch in tqdm(val_loader, desc=f\"Validation Epoch {epoch+1}\", leave=False):\n            text_input_ids1 = batch['input_ids1'].to(device)\n            text_attention_mask1 = batch['attention_mask1'].to(device)\n            text_input_ids2 = batch['input_ids2'].to(device)\n            text_attention_mask2 = batch['attention_mask2'].to(device)\n            labels = batch['labels'].to(device)\n            \n            outputs = model(text_input_ids1, text_attention_mask1, text_input_ids2, text_attention_mask2)\n            val_loss += nn.CrossEntropyLoss()(outputs, labels).item()\n            _, predicted = torch.max(outputs.data, 1)\n            total_val += labels.size(0)\n            correct_val += (predicted == labels).sum().item()\n\n    val_accuracy = 100 * correct_val / total_val\n    print(f'Epoch {epoch+1}/{EPOCHS}, Validation Loss: {val_loss/len(val_loader):.4f}, Validation Accuracy: {val_accuracy:.2f}%')\n\n    # Save the model if validation accuracy improves\n    best_val_accuracy = save_model(model, model_filepath, epoch, val_accuracy, best_val_accuracy)","metadata":{"execution":{"iopub.status.busy":"2025-01-02T11:07:13.513892Z","iopub.execute_input":"2025-01-02T11:07:13.514469Z","iopub.status.idle":"2025-01-02T12:11:39.314901Z","shell.execute_reply.started":"2025-01-02T11:07:13.514443Z","shell.execute_reply":"2025-01-02T12:11:39.314061Z"},"trusted":true},"outputs":[{"name":"stderr","text":"                                                                                     \r","output_type":"stream"},{"name":"stdout","text":"Epoch [1/2], Loss: 0.5029, Accuracy: 0.7575\n","output_type":"stream"},{"name":"stderr","text":"                                                                     \r","output_type":"stream"},{"name":"stdout","text":"Epoch 1/2, Validation Loss: 0.4325, Validation Accuracy: 80.19%\nModel saved at epoch 1 with validation accuracy: 80.19%\n","output_type":"stream"},{"name":"stderr","text":"                                                                                     \r","output_type":"stream"},{"name":"stdout","text":"Epoch [2/2], Loss: 0.3256, Accuracy: 0.8654\n","output_type":"stream"},{"name":"stderr","text":"                                                                     ","output_type":"stream"},{"name":"stdout","text":"Epoch 2/2, Validation Loss: 0.5261, Validation Accuracy: 78.80%\n","output_type":"stream"},{"name":"stderr","text":"\r","output_type":"stream"}],"execution_count":26},{"cell_type":"code","source":"# Define the model checkpoint and path to the saved weights\nmodel_checkpoint = 'csebuetnlp/banglabert'\nsaved_model_path = 'dual_bert_classifier_best.pth'\n\n# Recreate the model architecture\nmodel = CustomDualBanglaBERTModel(model_checkpoint=model_checkpoint)\n\n# Load the model weights from the saved file\nmodel.load_state_dict(torch.load(saved_model_path))\n\n# Send the model to the appropriate device\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel.to(device)\n\nprint(\"Custom model loaded successfully!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-02T12:22:11.497230Z","iopub.execute_input":"2025-01-02T12:22:11.497516Z","iopub.status.idle":"2025-01-02T12:22:14.574884Z","shell.execute_reply.started":"2025-01-02T12:22:11.497494Z","shell.execute_reply":"2025-01-02T12:22:14.573996Z"}},"outputs":[{"name":"stderr","text":"<ipython-input-30-699ca1464688>:9: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  model.load_state_dict(torch.load(saved_model_path))\n","output_type":"stream"},{"name":"stdout","text":"Custom model loaded successfully!\n","output_type":"stream"}],"execution_count":30},{"cell_type":"code","source":"\nfrom tqdm import tqdm\n\ndef batch_predict(loader):\n    model.eval()  # Set the model to evaluation mode\n    predictions = []\n\n    with torch.no_grad():\n        for batch in tqdm(loader, desc=\"Batch Prediction\", leave=False):\n            text_input_ids1 = batch['input_ids1'].to(device)\n            text_attention_mask1 = batch['attention_mask1'].to(device)\n            text_input_ids2 = batch['input_ids2'].to(device)\n            text_attention_mask2 = batch['attention_mask2'].to(device)\n            labels = batch['labels'].to(device)\n            outputs = model(text_input_ids1, text_attention_mask1, text_input_ids2, text_attention_mask2)\n            _, predicted = torch.max(outputs.data, 1)\n            predictions.extend(predicted.cpu().numpy())\n\n    return predictions\npred=batch_predict(val_loader)\ntrue=val_dataset.labels\n\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, roc_curve, auc, accuracy_score\nimport numpy as np\nfrom sklearn.metrics import precision_recall_fscore_support\nimport numpy as np\nfrom sklearn.preprocessing import label_binarize\n\n\n# Generate predictions and true labels\n\npred = np.array(pred)\ntrue_labels =np.array(true)\n\n\n\n# Calculate precision, recall, and F1 score for each class\nprecision, recall, f1, _ = precision_recall_fscore_support(true_labels, pred, average=None)\n\n# Get the unique labels\nlabels =np.array([0,1])\n\n# Print the precision, recall, and F1 score for each class\nfor i, label in enumerate(labels):\n    print(f\"Class {label}:\")\n    print(f\"  Precision: {precision[i]:.4f}\")\n    print(f\"  Recall:    {recall[i]:.4f}\")\n    print(f\"  F1 Score:  {f1[i]:.4f}\")\n\n# Optionally, you can calculate the average scores\navg_precision, avg_recall, avg_f1, _ = precision_recall_fscore_support(true_labels, pred, average='weighted')\n\nprint(f\"\\nAverage Precision: {avg_precision:.4f}\")\nprint(f\"Average Recall:    {avg_recall:.4f}\")\nprint(f\"Average F1 Score:  {avg_f1:.4f}\")\n\n# Compute accuracy\naccuracy = accuracy_score(true_labels, pred)\nprint(f'Accuracy: {accuracy:.4f}')\n\n# Print the number of samples for each class and total samples\nunique, counts = np.unique(true_labels, return_counts=True)\nclass_distribution = dict(zip(unique, counts))\ntotal_samples = len(true_labels)\nprint(f'Class Distribution: {class_distribution}')\nprint(f'Total Samples: {total_samples}')\n\n# Compute confusion matrix\ncm = confusion_matrix(true_labels, pred)\ndisp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=labels)\n\n# Plot confusion matrix\ndisp.plot(cmap=plt.cm.Blues)\nplt.title(\"Confusion Matrix\")\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-02T12:29:05.614132Z","iopub.execute_input":"2025-01-02T12:29:05.614416Z","iopub.status.idle":"2025-01-02T12:31:18.575214Z","shell.execute_reply.started":"2025-01-02T12:29:05.614395Z","shell.execute_reply":"2025-01-02T12:31:18.574440Z"}},"outputs":[{"name":"stderr","text":"                                                                   \r","output_type":"stream"},{"name":"stdout","text":"Class 0:\n  Precision: 0.8106\n  Recall:    0.7878\n  F1 Score:  0.7991\nClass 1:\n  Precision: 0.7936\n  Recall:    0.8159\n  F1 Score:  0.8046\n\nAverage Precision: 0.8021\nAverage Recall:    0.8019\nAverage F1 Score:  0.8018\nAccuracy: 0.8019\nClass Distribution: {0: 2564, 1: 2564}\nTotal Samples: 5128\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 2 Axes>","image/png":"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\n"},"metadata":{}}],"execution_count":32},{"cell_type":"code","source":"eval_df.head(3)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-01T13:16:30.700641Z","iopub.execute_input":"2025-01-01T13:16:30.700898Z","iopub.status.idle":"2025-01-01T13:16:30.708789Z","shell.execute_reply.started":"2025-01-01T13:16:30.700876Z","shell.execute_reply":"2025-01-01T13:16:30.708107Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# def preprocess_function(context,text):\n#     parent_encoding = tokenizer(context, padding=\"max_length\", truncation=True, max_length=128)\n#     text_encoding = tokenizer(context, padding=\"max_length\", truncation=True, max_length=128)\n    \n#     return {\n#         'input_ids1': parent_encoding['input_ids'],\n#         'attention_mask1': parent_encoding['attention_mask'],\n#         'input_ids2': text_encoding['input_ids'],\n#         'attention_mask2': text_encoding['attention_mask'],\n#     }","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-01T13:16:30.709512Z","iopub.execute_input":"2025-01-01T13:16:30.709738Z","iopub.status.idle":"2025-01-01T13:16:32.474728Z","shell.execute_reply.started":"2025-01-01T13:16:30.709717Z","shell.execute_reply":"2025-01-01T13:16:32.473773Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#batch=preprocess_function(data2.iloc[1011]['parent_comment'],data2.iloc[1011]['comment'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-01T13:16:32.475539Z","iopub.execute_input":"2025-01-01T13:16:32.475839Z","iopub.status.idle":"2025-01-01T13:16:32.481731Z","shell.execute_reply.started":"2025-01-01T13:16:32.475807Z","shell.execute_reply":"2025-01-01T13:16:32.481049Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# with torch.no_grad():\n#     text_input_ids1 = torch.tensor(batch['input_ids1']).unsqueeze(dim=0).to(device)\n#     text_attention_mask1 = torch.tensor(batch['attention_mask1']).unsqueeze(dim=0).to(device)\n#     text_input_ids2 =torch.tensor(batch['input_ids2']).unsqueeze(dim=0).to(device)\n#     text_attention_mask2 = torch.tensor(batch['attention_mask2']).unsqueeze(dim=0).to(device)\n    \n#     outputs = model(text_input_ids1, text_attention_mask1, text_input_ids2, text_attention_mask2).squeeze()\n#     print(np.argmax(outputs.cpu()))\n#     print(outputs)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-01T13:16:32.482427Z","iopub.execute_input":"2025-01-01T13:16:32.482641Z","iopub.status.idle":"2025-01-01T13:16:32.493344Z","shell.execute_reply.started":"2025-01-01T13:16:32.482623Z","shell.execute_reply":"2025-01-01T13:16:32.492536Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Using Concatenation Technique","metadata":{}},{"cell_type":"code","source":"data_twitter_df.head(3)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-01T13:16:32.494060Z","iopub.execute_input":"2025-01-01T13:16:32.494285Z","iopub.status.idle":"2025-01-01T13:16:32.509272Z","shell.execute_reply.started":"2025-01-01T13:16:32.494266Z","shell.execute_reply":"2025-01-01T13:16:32.508406Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# def concat_function(comment, parent):\n#     return comment + \" \" + parent\n\n# data_twitter_df['text'] = data_twitter_df.apply(lambda x: concat_function(x['comment'], x['parent_comment']), axis=1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-01T13:16:32.510234Z","iopub.execute_input":"2025-01-01T13:16:32.510501Z","iopub.status.idle":"2025-01-01T13:16:32.519784Z","shell.execute_reply.started":"2025-01-01T13:16:32.510480Z","shell.execute_reply":"2025-01-01T13:16:32.518929Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"data_twitter_df.head(2)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-01T13:16:32.520565Z","iopub.execute_input":"2025-01-01T13:16:32.520840Z","iopub.status.idle":"2025-01-01T13:16:32.535452Z","shell.execute_reply.started":"2025-01-01T13:16:32.520809Z","shell.execute_reply":"2025-01-01T13:16:32.534750Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"data_twitter_df_concat=data_twitter_df[['parent_comment','label']]\ndata_twitter_df_concat","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-01T13:16:32.536319Z","iopub.execute_input":"2025-01-01T13:16:32.536550Z","iopub.status.idle":"2025-01-01T13:16:32.552303Z","shell.execute_reply.started":"2025-01-01T13:16:32.536518Z","shell.execute_reply":"2025-01-01T13:16:32.551346Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_df, eval_df = train_test_split(data_twitter_df_concat, test_size=0.2, random_state=42, stratify=data_twitter_df_concat['label'])\n\n\ntrain_df.head(3)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-01T13:16:32.553126Z","iopub.execute_input":"2025-01-01T13:16:32.553348Z","iopub.status.idle":"2025-01-01T13:16:32.571763Z","shell.execute_reply.started":"2025-01-01T13:16:32.553329Z","shell.execute_reply":"2025-01-01T13:16:32.570878Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_df.label.value_counts()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-01T13:34:42.025305Z","iopub.execute_input":"2025-01-01T13:34:42.025620Z","iopub.status.idle":"2025-01-01T13:34:42.032632Z","shell.execute_reply.started":"2025-01-01T13:34:42.025594Z","shell.execute_reply":"2025-01-01T13:34:42.031801Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"eval_df.label.value_counts()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-01T13:34:50.795233Z","iopub.execute_input":"2025-01-01T13:34:50.795620Z","iopub.status.idle":"2025-01-01T13:34:50.803446Z","shell.execute_reply.started":"2025-01-01T13:34:50.795591Z","shell.execute_reply":"2025-01-01T13:34:50.802307Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model_checkpoint","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-01T13:16:32.572601Z","iopub.execute_input":"2025-01-01T13:16:32.572898Z","iopub.status.idle":"2025-01-01T13:16:32.578040Z","shell.execute_reply.started":"2025-01-01T13:16:32.572868Z","shell.execute_reply":"2025-01-01T13:16:32.577243Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"tokenizer","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-01T13:16:32.578856Z","iopub.execute_input":"2025-01-01T13:16:32.579077Z","iopub.status.idle":"2025-01-01T13:16:32.591025Z","shell.execute_reply.started":"2025-01-01T13:16:32.579055Z","shell.execute_reply":"2025-01-01T13:16:32.590193Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Print the original sentence.\ndem = 'আমি তোমাকে ভালবাসি।'\nprint(' Original: ', dem)\n\n# Print the sentence split into tokens.\nprint('Tokenized: ', tokenizer.tokenize(dem))\n\n# Print the sentence mapped to token ids.\nprint('Token IDs: ', tokenizer.convert_tokens_to_ids(tokenizer.tokenize(dem)))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-01T13:16:32.591872Z","iopub.execute_input":"2025-01-01T13:16:32.592188Z","iopub.status.idle":"2025-01-01T13:16:32.603762Z","shell.execute_reply.started":"2025-01-01T13:16:32.592156Z","shell.execute_reply":"2025-01-01T13:16:32.602967Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from transformers import AutoTokenizer,BertForSequenceClassification, Trainer, TrainingArguments,BertConfig\nfrom datasets import Dataset, DatasetDict\nfrom sklearn.model_selection import train_test_split\n\nfrom transformers import AutoTokenizer\n# train_df=augment_text(train_df)\n# print('augmentation finished..')\n# # Convert the pandas DataFrames to Hugging Face Datasets.\ntrain_dataset = Dataset.from_pandas(train_df)\n\neval_dataset = Dataset.from_pandas(eval_df)\n\n# Create a DatasetDict to hold the training and evaluation datasets.\ndataset_dict = DatasetDict({\n    'train': train_dataset,\n    'eval': eval_dataset\n})\n\n# Specify the checkpoint of the pre-trained model to use for tokenization.\n# model_checkpoint ='bert-base-uncased'\n\n# Load the tokenizer from the specified checkpoint.\ntokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n\n# Define a function to tokenize the input examples.\ndef tokenize_function(examples):\n    return tokenizer(examples['parent_comment'], truncation=True)\n\n# Apply the tokenization function to the datasets.\n# This tokenizes the 'text' field in each example, with batched processing for efficiency.\ntokenized_datasets = dataset_dict.map(tokenize_function, batched=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-01T13:16:32.604501Z","iopub.execute_input":"2025-01-01T13:16:32.604755Z","iopub.status.idle":"2025-01-01T13:16:35.929532Z","shell.execute_reply.started":"2025-01-01T13:16:32.604729Z","shell.execute_reply":"2025-01-01T13:16:35.928301Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from transformers import BertForSequenceClassification,AutoModelForSequenceClassification, TrainingArguments, Trainer, BertConfig, DataCollatorWithPadding\nfrom sklearn.metrics import accuracy_score\n# model_checkpoint='bert-base-uncased'\n\ndef compute_metrics(p):\n    logits, labels = p\n    predictions = logits.argmax(axis=-1)  # Get the predicted class\n    accuracy = accuracy_score(labels, predictions)\n    return {\"accuracy\": accuracy}\n# Load the configuration for BERT model from a pretrained model directory.\n# Adjust the dropout probabilities and specify the number of output labels.\n#model_config = BertConfig.from_pretrained(model_checkpoint, hidden_dropout_prob=0.40,  attention_probs_dropout_prob=0.15, num_labels=2)\n\n# Load the BERT model for sequence classification from a pretrained model directory.\n# The model is trained on a specific dataset relevant to the task.\nmodel = AutoModelForSequenceClassification.from_pretrained(model_checkpoint, num_labels=2)\n\nmodel","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-01T13:16:35.930887Z","iopub.execute_input":"2025-01-01T13:16:35.931221Z","iopub.status.idle":"2025-01-01T13:16:36.206621Z","shell.execute_reply.started":"2025-01-01T13:16:35.931186Z","shell.execute_reply":"2025-01-01T13:16:36.205637Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\n\n# Create a data collator that dynamically pads the inputs to the longest sequence in a batch.\ndata_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n\n# Define the training arguments for the Trainer with no model saving.\ntraining_args = TrainingArguments(\n    output_dir=\"./results\",              # Directory to save training logs (if any).\n    evaluation_strategy=\"epoch\",         # Evaluate the model at the end of each epoch.\n    save_strategy=\"no\",                  # Do not save the model during or after training.\n    learning_rate=2e-5,                  # Learning rate for the optimizer.\n    per_device_train_batch_size=8,      # Batch size for training.\n    per_device_eval_batch_size=8,       # Batch size for evaluation.\n    num_train_epochs=4,                  # Number of epochs to train the model.\n    weight_decay=0.01,                   # Weight decay to apply (if any).\n    load_best_model_at_end=False,        # Do not load the best model at the end of training.\n    report_to=\"none\"                     # Disable logging to W&B.\n)\n\n# Initialize the Trainer with the model, training arguments, datasets, tokenizer, and data collator.\ntrainer = Trainer(\n    model=model,                          # The model to train.\n    args=training_args,                   # Training arguments.\n    train_dataset=tokenized_datasets['train'],  # Training dataset.\n    eval_dataset=tokenized_datasets['eval'],    # Evaluation dataset.\n    tokenizer=tokenizer,                  # Tokenizer used for preprocessing.\n    data_collator=data_collator,          # Data collator for dynamic padding.\n    compute_metrics=compute_metrics       # Compute accuracy metric.\n)\n\n# Start the training process.\ntrainer.train()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-01T13:16:36.207538Z","iopub.execute_input":"2025-01-01T13:16:36.207813Z","iopub.status.idle":"2025-01-01T13:17:26.494692Z","shell.execute_reply.started":"2025-01-01T13:16:36.207791Z","shell.execute_reply":"2025-01-01T13:17:26.493632Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-01T13:17:26.495577Z","iopub.execute_input":"2025-01-01T13:17:26.495832Z","iopub.status.idle":"2025-01-01T13:17:26.501574Z","shell.execute_reply.started":"2025-01-01T13:17:26.495809Z","shell.execute_reply":"2025-01-01T13:17:26.500828Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nfrom sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, roc_curve, auc, accuracy_score\nimport numpy as np\nfrom sklearn.metrics import precision_recall_fscore_support\nimport numpy as np\n\n# Generate predictions and true labels\npredictions = trainer.predict(tokenized_datasets['eval'])\npreds = np.argmax(predictions.predictions, axis=1)\ntrue_labels = predictions.label_ids\n\n\n\n# Calculate precision, recall, and F1 score for each class\nprecision, recall, f1, _ = precision_recall_fscore_support(true_labels, preds, average=None)\n\n# Get the unique labels\nlabels = np.unique(true_labels)\n\n# Print the precision, recall, and F1 score for each class\nfor i, label in enumerate(labels):\n    print(f\"Class {label}:\")\n    print(f\"  Precision: {precision[i]:.2f}\")\n    print(f\"  Recall:    {recall[i]:.2f}\")\n    print(f\"  F1 Score:  {f1[i]:.2f}\")\n\n# Optionally, you can calculate the average scores\navg_precision, avg_recall, avg_f1, _ = precision_recall_fscore_support(true_labels, preds, average='weighted')\n\nprint(f\"\\nAverage Precision: {avg_precision:.2f}\")\nprint(f\"Average Recall:    {avg_recall:.2f}\")\nprint(f\"Average F1 Score:  {avg_f1:.2f}\")\n\n# Compute accuracy\naccuracy = accuracy_score(true_labels, preds)\nprint(f'Accuracy: {accuracy:.2f}')\n\n# Print the number of samples for each class and total samples\nunique, counts = np.unique(true_labels, return_counts=True)\nclass_distribution = dict(zip(unique, counts))\ntotal_samples = len(true_labels)\nprint(f'Class Distribution: {class_distribution}')\nprint(f'Total Samples: {total_samples}')\n\n# Compute confusion matrix\ncm = confusion_matrix(true_labels, preds)\ndisp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=model.config.id2label)\n\n# Plot confusion matrix\ndisp.plot(cmap=plt.cm.Blues)\nplt.title(\"Confusion Matrix\")\nplt.show()\n\n# Compute ROC curve and ROC area for each class\nfpr = dict()\ntpr = dict()\nroc_auc = dict()\nnum_classes = model.config.num_labels\n\nfor i in range(num_classes):\n    fpr[i], tpr[i], _ = roc_curve(true_labels, predictions.predictions[:, i], pos_label=i)\n    roc_auc[i] = auc(fpr[i], tpr[i])\n\n# Plot ROC curve for each class\nplt.figure()\ncolors = ['darkorange', 'blue', 'green', 'red']\nfor i in range(num_classes):\n    plt.plot(fpr[i], tpr[i], color=colors[i % len(colors)], lw=2, label=f'Class {i} ROC curve (area = {roc_auc[i]:.2f})')\n\nplt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('Receiver Operating Characteristic for Each Class')\nplt.legend(loc=\"lower right\")\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-01T13:17:26.502436Z","iopub.execute_input":"2025-01-01T13:17:26.502748Z","iopub.status.idle":"2025-01-01T13:17:27.925091Z","shell.execute_reply.started":"2025-01-01T13:17:26.502716Z","shell.execute_reply":"2025-01-01T13:17:27.924114Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"eval_df.reset_index(drop=True, inplace=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-01T13:31:02.761278Z","iopub.execute_input":"2025-01-01T13:31:02.761614Z","iopub.status.idle":"2025-01-01T13:31:02.765704Z","shell.execute_reply.started":"2025-01-01T13:31:02.761585Z","shell.execute_reply":"2025-01-01T13:31:02.764754Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"eval_df.head(10)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-01T13:31:15.398188Z","iopub.execute_input":"2025-01-01T13:31:15.398500Z","iopub.status.idle":"2025-01-01T13:31:15.406458Z","shell.execute_reply.started":"2025-01-01T13:31:15.398476Z","shell.execute_reply":"2025-01-01T13:31:15.405639Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"text = eval_df['parent_comment'][7]\ntext","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-01T13:31:27.377334Z","iopub.execute_input":"2025-01-01T13:31:27.377646Z","iopub.status.idle":"2025-01-01T13:31:27.382897Z","shell.execute_reply.started":"2025-01-01T13:31:27.377616Z","shell.execute_reply":"2025-01-01T13:31:27.381962Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def predict(text):\n    # Tokenize the input text\n    inputs = tokenizer(text, return_tensors='pt', truncation=True, padding=True, max_length=128)\n    \n    # Move inputs to the same device as the model (GPU or CPU)\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    model.to(device)\n    inputs = {key: value.to(device) for key, value in inputs.items()}\n    \n    # Make predictions\n    with torch.no_grad():\n        outputs = model(**inputs)\n        logits = outputs.logits\n    \n    # Get the predicted class (0 or 1)\n    predicted_class = torch.argmax(logits, dim=-1).item()\n\n    return predicted_class\n\npredict(text)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-01T13:31:33.640286Z","iopub.execute_input":"2025-01-01T13:31:33.640577Z","iopub.status.idle":"2025-01-01T13:31:33.662570Z","shell.execute_reply.started":"2025-01-01T13:31:33.640554Z","shell.execute_reply":"2025-01-01T13:31:33.661932Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"preds[:10]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-01T13:29:46.494268Z","iopub.execute_input":"2025-01-01T13:29:46.494552Z","iopub.status.idle":"2025-01-01T13:29:46.499912Z","shell.execute_reply.started":"2025-01-01T13:29:46.494526Z","shell.execute_reply":"2025-01-01T13:29:46.499050Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"true_labels[:10]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-01T13:29:41.527008Z","iopub.execute_input":"2025-01-01T13:29:41.527291Z","iopub.status.idle":"2025-01-01T13:29:41.532827Z","shell.execute_reply.started":"2025-01-01T13:29:41.527270Z","shell.execute_reply":"2025-01-01T13:29:41.531773Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Semiase Architecture","metadata":{}},{"cell_type":"code","source":"import torch\nfrom torch.utils.data import Dataset\n\nclass MultiFeatureDataset(Dataset):\n    def __init__(self, dataframe, tokenizer, max_len):\n        self.tokenizer = tokenizer\n        self.data = dataframe\n        self.comment = dataframe['comment']\n        self.parent=dataframe['parent_comment']\n        self.labels = dataframe.label\n        self.max_len = max_len\n\n    def __len__(self):\n        return len(self.data)\n    \n    def __getitem__(self, index):\n        if index >= len(self.data):\n            raise IndexError(f\"Index {index} out of range\")\n        comment = str(self.comment.iloc[index])\n        parent = str(self.parent.iloc[index])\n        label = self.labels.iloc[index]\n\n\n \n        comment_encoding = self.tokenizer.encode_plus(\n            comment,\n            add_special_tokens=True,\n            max_length=self.max_len,\n            return_token_type_ids=False,\n            padding='max_length',\n            truncation=True,\n            return_attention_mask=True,\n            return_tensors='pt',\n        )\n\n        parent_encoding = self.tokenizer.encode_plus(\n            parent,\n            add_special_tokens=True,\n            max_length=self.max_len,\n            return_token_type_ids=False,\n            padding='max_length',\n            truncation=True,\n            return_attention_mask=True,\n            return_tensors='pt',\n        )\n\n        return {\n        'input_ids1': parent_encoding['input_ids'].flatten(),\n        'attention_mask1': parent_encoding['attention_mask'].flatten(),\n        'input_ids2': comment_encoding['input_ids'].flatten(),\n        'attention_mask2': comment_encoding['attention_mask'].flatten(),\n        'labels': torch.tensor(label, dtype=torch.long)\n    }\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-01T13:17:27.926257Z","iopub.execute_input":"2025-01-01T13:17:27.926612Z","iopub.status.idle":"2025-01-01T13:17:27.933525Z","shell.execute_reply.started":"2025-01-01T13:17:27.926575Z","shell.execute_reply":"2025-01-01T13:17:27.932670Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nfrom transformers import AutoModel\n\nclass SemiaseBERT(nn.Module):\n    def __init__(self, hidden_size=768):\n        super(SemiaseBERT, self).__init__()\n        \n        # Two BERT models: one for each input\n        self.bert1 = AutoModel.from_pretrained('bert-base-uncased')\n        self.bert2 = AutoModel.from_pretrained('bert-base-uncased')\n        \n        # Fully connected layer for classification\n        self.fc = nn.Linear(hidden_size * 2, 2)  # Multiply by 2 for concatenation\n\n    def forward(self, input_ids1, attention_mask1, input_ids2, attention_mask2):\n        # Get BERT embeddings (pooled output or CLS token output)\n        output1 = self.bert1(input_ids=input_ids1, attention_mask=attention_mask1).pooler_output  # [batch_size, hidden_size]\n        output2 = self.bert2(input_ids=input_ids2, attention_mask=attention_mask2).pooler_output  # [batch_size, hidden_size]\n        \n        # Concatenate the pooled outputs\n        combined = torch.cat((output1, output2), dim=1)  # [batch_size, hidden_size * 2]\n        \n        # Pass through the fully connected layer\n        return self.fc(combined)  # [batch_size, 2]\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-01T13:17:27.934521Z","iopub.execute_input":"2025-01-01T13:17:27.934844Z","iopub.status.idle":"2025-01-01T13:17:27.949405Z","shell.execute_reply.started":"2025-01-01T13:17:27.934811Z","shell.execute_reply":"2025-01-01T13:17:27.948749Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"data_twitter_df.head(3)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-01T13:17:27.950096Z","iopub.execute_input":"2025-01-01T13:17:27.950309Z","iopub.status.idle":"2025-01-01T13:17:27.968174Z","shell.execute_reply.started":"2025-01-01T13:17:27.950289Z","shell.execute_reply":"2025-01-01T13:17:27.967242Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# import torch\n# import torch.nn as nn\n# from torch.utils.data import DataLoader\n# from transformers import BertTokenizer, AdamW,AutoModel,AutoTokenizer\n# from tqdm import tqdm  # Import tqdm for progress bars\n\n# # Hyperparameters\n# MAX_LEN = 128\n# BATCH_SIZE = 16\n# EPOCHS = 5\n# LEARNING_RATE = 2e-5\n\n# tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')\n# train_df, eval_df = train_test_split(data_twitter_df, test_size=0.2, random_state=42, stratify=data_twitter_df['label'])\n# # Create data loaders\n# train_dataset = MultiFeatureDataset(train_df, tokenizer, MAX_LEN)\n# val_dataset = MultiFeatureDataset(eval_df, tokenizer, MAX_LEN)\n\n# train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n# val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE)\n\n# # Initialize the model\n\n# # Usage\n# model = SemiaseBERT()\n# #model.load_state_dict(torch.load('dual_bert_classifier.pth'))\n\n\n# # Optimizer with weight decay\n# from transformers import AdamW, get_linear_schedule_with_warmup\n\n\n# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n# model = model.to(device)\n\n# optimizer = AdamW(model.parameters(), lr=2e-5, weight_decay=0.01)\n\n\n# model.cuda()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-01T13:17:27.969109Z","iopub.execute_input":"2025-01-01T13:17:27.969406Z","iopub.status.idle":"2025-01-01T13:17:27.979194Z","shell.execute_reply.started":"2025-01-01T13:17:27.969372Z","shell.execute_reply":"2025-01-01T13:17:27.978324Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\n# # Training loop\n# for epoch in range(EPOCHS):\n#     model.train()\n#     running_loss = 0.0\n#     correct_train = 0\n#     total_train = 0\n    \n#     # Initialize the tqdm progress bar\n#     progress_bar = tqdm(train_loader, desc=f\"Training Epoch {epoch+1}\", leave=False)\n    \n#     for batch_idx,batch in enumerate(progress_bar):\n#         text_input_ids1 = batch['input_ids1'].to(device)\n#         text_attention_mask1 = batch['attention_mask1'].to(device)\n#         text_input_ids2 = batch['input_ids2'].to(device)\n#         text_attention_mask2 = batch['attention_mask2'].to(device)\n#         labels = batch['labels'].to(device)\n        \n#         optimizer.zero_grad()\n        \n#         # Forward pass\n#         outputs = model(text_input_ids1, text_attention_mask1, text_input_ids2, text_attention_mask2)\n        \n#         # Calculate loss\n#         loss = nn.CrossEntropyLoss()(outputs, labels)\n        \n#         # Backward pass and optimization\n#         loss.backward()\n#         optimizer.step()\n        \n#         # Update running loss and accuracy\n#         running_loss += loss.item()\n#         _, predicted = torch.max(outputs.data, 1)\n#         total_train += labels.size(0)\n#         correct_train += (predicted == labels).sum().item()\n        \n#         avg_loss = running_loss / (batch_idx + 1)\n\n#         # Update the progress bar with the average loss\n#         progress_bar.set_postfix(avg_loss=avg_loss)\n\n#     # Optional: Print statistics at the end of each epoch\n#     epoch_loss = running_loss / len(train_loader)\n#     epoch_acc = correct_train / total_train\n#     print(f\"Epoch [{epoch+1}/{EPOCHS}], Loss: {epoch_loss:.4f}, Accuracy: {epoch_acc:.4f}\")\n#     # Validation\n#     model.eval()\n#     val_loss = 0\n#     correct_val = 0\n#     total_val = 0\n#     with torch.no_grad():\n#         for batch in tqdm(val_loader, desc=f\"Validation Epoch {epoch+1}\", leave=False):\n#             text_input_ids1 = batch['input_ids1'].to(device)\n#             text_attention_mask1 = batch['attention_mask1'].to(device)\n#             text_input_ids2 = batch['input_ids2'].to(device)\n#             text_attention_mask2 = batch['attention_mask2'].to(device)\n#             labels = batch['labels'].to(device)\n            \n    \n#             outputs = model(text_input_ids1, text_attention_mask1, text_input_ids2, text_attention_mask2)\n#             val_loss += nn.CrossEntropyLoss()(outputs, labels).item()\n#             _, predicted = torch.max(outputs.data, 1)\n#             total_val += labels.size(0)\n#             correct_val += (predicted == labels).sum().item()\n\n#     val_accuracy = 100 * correct_val / total_val\n#     print(f'Epoch {epoch+1}/{EPOCHS}, Validation Loss: {val_loss/len(val_loader):.4f}, Validation Accuracy: {val_accuracy:.2f}%')\n\n# # Save the model\n# torch.save(model.state_dict(), 'dual_bert_classifier2.pth')\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-01T13:17:27.980145Z","iopub.execute_input":"2025-01-01T13:17:27.980371Z","iopub.status.idle":"2025-01-01T13:17:27.994724Z","shell.execute_reply.started":"2025-01-01T13:17:27.980350Z","shell.execute_reply":"2025-01-01T13:17:27.993947Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\n# from tqdm import tqdm\n\n# def batch_predict(loader):\n#     model.eval()  # Set the model to evaluation mode\n#     predictions = []\n\n#     with torch.no_grad():\n#         for batch in tqdm(loader, desc=\"Batch Prediction\", leave=False):\n#             text_input_ids1 = batch['input_ids1'].to(device)\n#             text_attention_mask1 = batch['attention_mask1'].to(device)\n#             text_input_ids2 = batch['input_ids2'].to(device)\n#             text_attention_mask2 = batch['attention_mask2'].to(device)\n#             labels = batch['labels'].to(device)\n#             outputs = model(text_input_ids1, text_attention_mask1, text_input_ids2, text_attention_mask2)\n#             _, predicted = torch.max(outputs.data, 1)\n#             predictions.extend(predicted.cpu().numpy())\n\n#     return predictions\n# pred=batch_predict(val_loader)\n# true=val_dataset.labels\n\n# import matplotlib.pyplot as plt\n# from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, roc_curve, auc, accuracy_score\n# import numpy as np\n# from sklearn.metrics import precision_recall_fscore_support\n# import numpy as np\n# from sklearn.preprocessing import label_binarize\n\n\n# # Generate predictions and true labels\n\n# pred = np.array(pred)\n# true_labels =np.array(true)\n\n\n\n# # Calculate precision, recall, and F1 score for each class\n# precision, recall, f1, _ = precision_recall_fscore_support(true_labels, pred, average=None)\n\n# # Get the unique labels\n# labels =np.array([0,1])\n\n# # Print the precision, recall, and F1 score for each class\n# for i, label in enumerate(labels):\n#     print(f\"Class {label}:\")\n#     print(f\"  Precision: {precision[i]:.2f}\")\n#     print(f\"  Recall:    {recall[i]:.2f}\")\n#     print(f\"  F1 Score:  {f1[i]:.2f}\")\n\n# # Optionally, you can calculate the average scores\n# avg_precision, avg_recall, avg_f1, _ = precision_recall_fscore_support(true_labels, pred, average='weighted')\n\n# print(f\"\\nAverage Precision: {avg_precision:.2f}\")\n# print(f\"Average Recall:    {avg_recall:.2f}\")\n# print(f\"Average F1 Score:  {avg_f1:.2f}\")\n\n# # Compute accuracy\n# accuracy = accuracy_score(true_labels, pred)\n# print(f'Accuracy: {accuracy:.2f}')\n\n# # Print the number of samples for each class and total samples\n# unique, counts = np.unique(true_labels, return_counts=True)\n# class_distribution = dict(zip(unique, counts))\n# total_samples = len(true_labels)\n# print(f'Class Distribution: {class_distribution}')\n# print(f'Total Samples: {total_samples}')\n\n# # Compute confusion matrix\n# cm = confusion_matrix(true_labels, pred)\n# disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=labels)\n\n# # Plot confusion matrix\n# disp.plot(cmap=plt.cm.Blues)\n# plt.title(\"Confusion Matrix\")\n# plt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-01T13:17:27.995616Z","iopub.execute_input":"2025-01-01T13:17:27.995929Z","iopub.status.idle":"2025-01-01T13:17:28.007382Z","shell.execute_reply.started":"2025-01-01T13:17:27.995901Z","shell.execute_reply":"2025-01-01T13:17:28.006746Z"}},"outputs":[],"execution_count":null}]}